# ğŸ§  ASKyourPDF

ASKyourPDF is an AI-powered PDF question-answering tool that uses **Retrieval-Augmented Generation (RAG)**. It allows users to upload a PDF and ask questions about its content using **Nomic embeddings** and **LLaMA 3** for local language understanding.

---

## ğŸš€ Features

- ğŸ“„ Upload and interact with your PDFs
- ğŸ§  Powered by `nomic-embed-text` for vector embeddings
- ğŸ¤– Uses `llama3` via [Ollama](https://ollama.com) for local LLM inference
- ğŸ” RAG pipeline for accurate and contextual responses
- ğŸ–¥ï¸ Streamlit-based frontend (or easily replaceable with a custom UI)

---

## ğŸ“ Project Structure

```
ASKyourPDF/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/              # Streamlit application
â”‚   â”‚   â”œâ”€â”€ components/   # UI components (chat, PDF viewer, sidebar)
â”‚   â”‚   â””â”€â”€ main.py       # Main app file
â”‚   â””â”€â”€ core/             # Core logic
â”‚       â”œâ”€â”€ document.py   # PDF processing & chunking
â”‚       â”œâ”€â”€ embeddings.py # Nomic embedding integration
â”‚       â”œâ”€â”€ llm.py        # LLaMA model integration
â”‚       â””â”€â”€ rag.py        # RAG pipeline logic
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/             # Uploaded PDFs
â”‚   â”‚   â””â”€â”€ sample/       # Sample PDF
â”‚   â””â”€â”€ vectors/          # Chroma vector DB
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ run.py                # Entry point
```

---

## ğŸ§© Requirements

- Python 3.9+
- [Ollama](https://ollama.com/) (for running `llama3` and `nomic-embed-text`)
- Chroma DB
- Streamlit

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/ram-rk-cmd/ASKyourPDF.git
cd ASKyourPDF
```

### 2. Set Up Python Environment

```bash
python -m venv venv
.env\Scriptsctivate  # On Windows
# Or:
# source venv/bin/activate  # On macOS/Linux
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Pull Required Ollama Models

```bash
ollama pull llama3
ollama pull nomic-embed-text
```

### 5. Run the App

```bash
python run.py
```

Then open your browser to:  
ğŸ“ `http://localhost:8501`

---

## ğŸ“¦ Tech Stack

- **LLM**: LLaMA 3 via Ollama (`llama3`)
- **Embeddings**: Nomic (`nomic-embed-text`)
- **Vector DB**: Chroma
- **Frontend**: Streamlit (can be swapped with custom UI)
- **Frameworks**: Python, FastAPI (optional), LangChain-style logic

---

## ğŸ› ï¸ To-Do / Enhancements

- [ ] Add support for multiple PDFs
- [ ] Add custom UI with FastAPI + React
- [ ] Enable persistent session memory
- [ ] Dockerize the project

---

## ğŸ§ª Running Tests

```bash
pytest tests/
```

---

## ğŸ“œ License

MIT License â€“ see `LICENSE` file for details.

---

## ğŸ™‹â€â™‚ï¸ Author

Made with â¤ï¸ by [@ram-rk-cmd](https://github.com/ram-rk-cmd)
